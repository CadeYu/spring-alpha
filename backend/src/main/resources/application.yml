spring:
  application:
    name: spring-alpha-backend
  
  # PostgreSQL (Neon) Configuration
  datasource:
    url: jdbc:postgresql://ep-super-night-a1grbtke-pooler.ap-southeast-1.aws.neon.tech/neondb?sslmode=require
    username: ${NEON_USERNAME:neondb_owner}
    password: ${NEON_PASSWORD:}
    driver-class-name: org.postgresql.Driver
    hikari:
      connection-timeout: 30000       # 30s 连接超时
      idle-timeout: 600000            # 10m 空闲超时
      max-lifetime: 1800000           # 30m 最大生命周期
      minimum-idle: 2                 # 最小空闲连接
      maximum-pool-size: 10           # 最大连接数
  
  jpa:
    hibernate:
      ddl-auto: update
    database-platform: org.hibernate.dialect.PostgreSQLDialect
    show-sql: false
  
  # Spring AI Configuration
  ai:
    # OpenAI (Groq) - 当前主力
    openai:
      base-url: https://api.groq.com/openai
      # 使用环境变量注入，默认值为空 (防止 GitHub 泄露)
      api-key: ${GROQ_API_KEY:}
      chat:
        options:
          model: llama-3.3-70b-versatile
    
    # Vertex AI (Gemini) - 备用，防止 GeminiStrategy 启动报错
    vertex:
      ai:
        gemini:
          api-key: ${GEMINI_API_KEY:placeholder_key}
    
    # PGVector 向量存储配置
    vectorstore:
      pgvector:
        initialize-schema: true  # 自动创建 vector_store 表
        dimensions: 768           # gemini-embedding-001 is 768 dimensions
        index-type: NONE          # HNSW 最大只支持 2000 维，暂时禁用索引
        distance-type: COSINE_DISTANCE




app:
  # 嵌入模型提供商: local (ONNX, 免费本地) | gemini (Google API)
  embedding-provider: gemini
  
  # 切换默认策略：groq (Groq Llama 3.3) | openai | gemini | enhanced-mock (测试)
  ai-provider: groq  # ← 切换回 Groq (Llama 3.3)
  
  # OpenAI Configuration (optional - requires OPENAI_API_KEY)
  openai:
    enabled: true
    api-key: ${OPENAI_API_KEY:}
    model: ${OPENAI_MODEL:gpt-4o-mini}
    base-url: ${OPENAI_BASE_URL:https://api.openai.com/v1}
  
  # Gemini Configuration (optional - requires GEMINI_API_KEY)
  gemini:
    enabled: true
    api-key: ${GEMINI_API_KEY:}
    model: gemini-2.0-flash  # Updated to available model
  
  # Financial Modeling Prep API Configuration (Updated Feb 2026)
  # API key is loaded from environment variable (set in start_backend.sh)
  fmp:
    api-key: ${FMP_API_KEY:}
    base-url: https://financialmodelingprep.com/stable

server:
  port: 8081

logging:
  level:
    root: INFO
    com.springalpha: DEBUG
