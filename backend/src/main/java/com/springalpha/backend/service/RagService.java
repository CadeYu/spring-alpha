package com.springalpha.backend.service;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.stereotype.Service;

import java.util.*;

/**
 * ç®€æ˜“ RAG (Retrieval-Augmented Generation) æœåŠ¡
 * 
 * åŠŸèƒ½ï¼šå°†é•¿æ–‡æœ¬åˆ†å‰²æˆ chunksï¼ŒåŸºäºå…³é”®è¯åŒ¹é…æ£€ç´¢æœ€ç›¸å…³çš„ç‰‡æ®µ
 * 
 * æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªç®€åŒ–ç‰ˆå®ç°ï¼Œä½¿ç”¨å…³é”®è¯åŒ¹é…è€Œéå‘é‡åµŒå…¥ã€‚
 * ç”Ÿäº§ç¯å¢ƒå»ºè®®é›†æˆ Spring AI çš„ VectorStore (å¦‚ PGVector, Pinecone)ã€‚
 */
@Service
public class RagService {

    private static final Logger log = LoggerFactory.getLogger(RagService.class);
    
    // Chunk å¤§å° (å­—ç¬¦æ•°) - å¢å¤§ä»¥å‡å°‘ chunk æ•°é‡
    private static final int CHUNK_SIZE = 4000;
    // Chunk æ­¥è¿› (æ— é‡å ï¼Œç®€åŒ–é€»è¾‘)
    private static final int CHUNK_STEP = 3800;
    // è¿”å›çš„ Top K ä¸ªæœ€ç›¸å…³ç‰‡æ®µ
    private static final int TOP_K = 4;
    // æœ€ç»ˆä¸Šä¸‹æ–‡æœ€å¤§é•¿åº¦ (é˜²æ­¢ Token è¶…é™)
    private static final int MAX_CONTEXT_LENGTH = 12000;

    /**
     * ä»é•¿æ–‡æœ¬ä¸­æ£€ç´¢ä¸ query æœ€ç›¸å…³çš„å†…å®¹ç‰‡æ®µ
     * 
     * @param fullText  å®Œæ•´çš„ SEC 10-K æ–‡æœ¬
     * @param query     ç”¨æˆ·æŸ¥è¯¢æˆ–é¢„è®¾çš„æ£€ç´¢å…³é”®è¯
     * @return          æ‹¼æ¥åçš„ç›¸å…³ä¸Šä¸‹æ–‡
     */
    public String retrieveRelevantContext(String fullText, String query) {
        log.info("ğŸ“š RAG å¼€å§‹å¤„ç†ï¼ŒåŸæ–‡é•¿åº¦: {} å­—ç¬¦", fullText.length());
        
        // å®‰å…¨æ£€æŸ¥ï¼šå¦‚æœæ–‡æœ¬å¤ªçŸ­ï¼Œç›´æ¥è¿”å›
        if (fullText.length() <= MAX_CONTEXT_LENGTH) {
            log.info("ğŸ“¦ æ–‡æœ¬é•¿åº¦å°äºä¸Šä¸‹æ–‡é™åˆ¶ï¼Œç›´æ¥è¿”å›å…¨æ–‡");
            return fullText;
        }
        
        // 1. åˆ†å‰²æ–‡æœ¬ä¸º chunks (å†…å­˜ä¼˜åŒ–ç‰ˆ)
        List<ChunkInfo> chunkInfos = splitIntoChunksOptimized(fullText);
        log.info("ğŸ“¦ åˆ†å‰²ä¸º {} ä¸ª chunks", chunkInfos.size());
        
        // 2. æå–æŸ¥è¯¢å…³é”®è¯
        Set<String> queryTerms = extractQueryTerms(query);
        log.info("ğŸ”‘ æ£€ç´¢å…³é”®è¯: {}", queryTerms);
        
        // 3. è®¡ç®—æ¯ä¸ª chunk çš„ç›¸å…³æ€§å¾—åˆ† (ä¸å­˜å‚¨å®Œæ•´æ–‡æœ¬ï¼Œåªå­˜å‚¨ä½ç½®)
        List<ScoredChunk> scoredChunks = new ArrayList<>();
        for (ChunkInfo info : chunkInfos) {
            // æå– chunk æ–‡æœ¬ç”¨äºè¯„åˆ†
            String chunkText = fullText.substring(info.start, info.end);
            double score = calculateRelevanceScore(chunkText, queryTerms);
            scoredChunks.add(new ScoredChunk(info.index, info.start, info.end, score));
        }
        
        // 4. æŒ‰å¾—åˆ†æ’åºï¼Œå– Top K
        scoredChunks.sort((a, b) -> Double.compare(b.score, a.score));
        List<ScoredChunk> topChunks = new ArrayList<>(
            scoredChunks.subList(0, Math.min(TOP_K, scoredChunks.size()))
        );
        
        // 5. æŒ‰åŸå§‹é¡ºåºæ’åˆ— (ä¿æŒæ–‡æ¡£ç»“æ„)
        topChunks.sort(Comparator.comparingInt(c -> c.index));
        
        // 6. æ‹¼æ¥ç»“æœ
        StringBuilder context = new StringBuilder();
        for (ScoredChunk sc : topChunks) {
            String chunkText = fullText.substring(sc.start, sc.end);
            if (context.length() + chunkText.length() > MAX_CONTEXT_LENGTH) {
                break;
            }
            context.append(chunkText).append("\n\n---\n\n");
        }
        
        String result = context.toString().trim();
        log.info("âœ… RAG æ£€ç´¢å®Œæˆï¼Œè¿”å›ä¸Šä¸‹æ–‡é•¿åº¦: {} å­—ç¬¦ (Top {} chunks)", result.length(), topChunks.size());
        
        return result;
    }

    /**
     * å†…å­˜ä¼˜åŒ–ç‰ˆåˆ†å‰² - åªå­˜å‚¨ä½ç½®ä¿¡æ¯ï¼Œä¸å­˜å‚¨å®Œæ•´æ–‡æœ¬
     */
    private List<ChunkInfo> splitIntoChunksOptimized(String text) {
        List<ChunkInfo> chunks = new ArrayList<>();
        int textLen = text.length();
        int index = 0;
        int start = 0;
        
        while (start < textLen) {
            int end = Math.min(start + CHUNK_SIZE, textLen);
            chunks.add(new ChunkInfo(index++, start, end));
            start += CHUNK_STEP;
        }
        
        return chunks;
    }

    /**
     * æå–æŸ¥è¯¢ä¸­çš„å…³é”®è¯
     */
    private Set<String> extractQueryTerms(String query) {
        String[] terms = query.toLowerCase()
                .replaceAll("[^a-zA-Z0-9,\\s]", "")
                .split("[,\\s]+");
        
        Set<String> stopWords = Set.of("the", "a", "an", "and", "or", "but", "in", "on", "at", "to", "for", "of", "with");
        Set<String> result = new HashSet<>();
        for (String term : terms) {
            if (term.length() > 2 && !stopWords.contains(term)) {
                result.add(term);
            }
        }
        return result;
    }

    /**
     * è®¡ç®— chunk ä¸æŸ¥è¯¢çš„ç›¸å…³æ€§å¾—åˆ† (ç®€å•çš„å…³é”®è¯åŒ¹é…)
     */
    private double calculateRelevanceScore(String chunk, Set<String> queryTerms) {
        String lowerChunk = chunk.toLowerCase();
        double score = 0.0;
        
        for (String term : queryTerms) {
            if (lowerChunk.contains(term)) {
                score += 1.0;
            }
        }
        
        // å¯¹åŒ…å«å…³é”®è´¢åŠ¡æœ¯è¯­çš„ chunk åŠ åˆ†
        String[] bonusTerms = {"revenue", "income", "profit", "loss", "risk", "guidance", "outlook", "growth", "margin", "cash flow"};
        for (String bonus : bonusTerms) {
            if (lowerChunk.contains(bonus)) {
                score += 0.5;
            }
        }
        
        return score;
    }

    /**
     * Chunk ä½ç½®ä¿¡æ¯ (å†…å­˜ä¼˜åŒ–)
     */
    private static class ChunkInfo {
        int index;
        int start;
        int end;

        ChunkInfo(int index, int start, int end) {
            this.index = index;
            this.start = start;
            this.end = end;
        }
    }

    /**
     * å¸¦è¯„åˆ†çš„ Chunk (å­˜å‚¨ä½ç½®è€Œéæ–‡æœ¬)
     */
    private static class ScoredChunk {
        int index;
        int start;
        int end;
        double score;

        ScoredChunk(int index, int start, int end, double score) {
            this.index = index;
            this.start = start;
            this.end = end;
            this.score = score;
        }
    }
}
